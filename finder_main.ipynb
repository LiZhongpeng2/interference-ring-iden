{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a742ca",
   "metadata": {},
   "source": [
    "# Statement\n",
    "\n",
    "The image we are going to process is a two-color interference image with red and black phases. Therefore, I firstly perform binarization processing on it to convert the color three-channel image into a two-channel grayscale image.\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"./image/orginal_image.png\" width=\"45%\" height=\"\"/>\n",
    "  <img src=\"./image/result.png\" width=\"45%\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297bd20-33da-4786-83e1-002050fcf09b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'finder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfinder\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'finder'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import finder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261c0562",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "- Read image file as a openCV format - BGR\n",
    "- Convert BGR image to 1 channel grayscale\n",
    "- Applies Gaussian smoothing with a 5×5 kernel to reduce high-frequency noise\n",
    "- Binarizes the image using a fixed threshold (threshold_val=40)\n",
    "- Performs opening to remove small white pepper noise\n",
    "- Figuring labels connected regions in the binary image and filtering \"pepper noise\" again "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d8ad03",
   "metadata": {},
   "source": [
    "_NOTE: This recognition algorithm is mainly based on image recognition. Of course, it can be modified for the recognition of interference rings in real-time video_\n",
    "\n",
    "Read the image and convert it into a channel of grayscale image for later processing firstly. Then, perform Gaussian blur processing on it to initially reduce noise interference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef423b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and preprocessing\n",
    "img = cv2.imread(\"test/img.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (5,5), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df4f9ed",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "- **Threshold value:** 40\n",
    "\n",
    "- **Max value:** 255 (pixels above the threshold are set to this value)\n",
    "\n",
    "- **Method:** cv2.THRESH_BINARY (standard binary thresholding)\n",
    "\n",
    "After multiple rounds of empirical tuning, I determined that a threshold value of 40 provides the best balance.\n",
    "This setting allows the bright and dark fringes in the interference pattern to remain clearly visible, while significantly suppressing background noise and artifacts. As a result, the binary image retains essential structural features without being overwhelmed by minor disturbances, making it an effective preprocessing step for downstream morphological and contour-based operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e8042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thresholding\n",
    "threshold_val = 40\n",
    "_, binary = cv2.threshold(blur, threshold_val, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac72ceb2",
   "metadata": {},
   "source": [
    "### Morphological Opening\n",
    "\n",
    "To remove small isolated white noise from the binary image, I applied a **morphological opening** operation, which consists of an erosion followed by a dilation.\n",
    "\n",
    "- **Kernel shape**: 4×4 rectangular structuring element  \n",
    "- **Purpose**: Effectively eliminates small white spots and smooths the object contours  \n",
    "- This step enhances the clarity of the target fringe regions by cleaning up minor foreground noise, preparing the image for more accurate component analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open operation\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4, 4))\n",
    "opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2603ba01",
   "metadata": {},
   "source": [
    "### Connected Component Filtering\n",
    "\n",
    "After morphological cleaning, I performed **connected component analysis** to identify and isolate meaningful regions based on area.\n",
    "\n",
    "- **connectedComponentsWithStats** provides detailed statistics (`area`, `bounding box`, etc.) for each connected region.\n",
    "- I skipped the background (`i = 0`) and filtered components by **area size** between **300 and 2800** pixels.\n",
    "- This filtering helps exclude both small noise blobs and overly large irrelevant regions, retaining only target-like features in the image.\n",
    "- The result is a clean binary mask (`clean`) containing candidate areas suitable for further processing such as center detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a827d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean\n",
    "num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(opened, connectivity=8)\n",
    "clean = np.zeros_like(gray)\n",
    "\n",
    "for i in range(1, num_labels):\n",
    "    area = stats[i, cv2.CC_STAT_AREA]\n",
    "    if 300 < area < 2800:\n",
    "        clean[labels == i] = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67413ea2",
   "metadata": {},
   "source": [
    "### Circle Center Detection via Voting\n",
    "\n",
    "To locate the center of the circular interference pattern, I used a custom **voting-based center detection** algorithm:\n",
    "\n",
    "- **Input**: `clean` — the binary image after noise removal and region filtering  \n",
    "- **Parameter**: `100` — the radius or neighborhood range used for center voting  \n",
    "- **Method**: This function scans the bright regions and allows each pixel to \"vote\" for possible circle centers within a defined radius. The point with the highest votes is considered the most probable center.\n",
    "\n",
    "This method is robust to slight distortions and noise, and works well for detecting approximate geometric centers in fringe-like patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = finder.find_circle_center_voting(clean,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d166f80",
   "metadata": {},
   "source": [
    "### Visualizing the Detected Center\n",
    "\n",
    "To visualize the detected circle center on the original image:\n",
    "\n",
    "- `img.copy()` creates a copy to avoid modifying the original image.  \n",
    "- `cv2.circle` draws a filled circle (`-1` thickness) of radius 5 pixels at the detected center `(x0, y0)` in **magenta** (BGR: (255, 0, 255)).  \n",
    "- `cv2.imshow` opens a window to display the image with the marked center.  \n",
    "- `cv2.waitKey(0)` waits indefinitely for a key press to proceed.  \n",
    "- `cv2.destroyAllWindows()` closes the display window properly.\n",
    "\n",
    "This step helps intuitively verify the accuracy of the center detection algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = img.copy()\n",
    "cv2.circle(output, (int(x0), int(y0)), 5, (255, 0, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Center Result\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
